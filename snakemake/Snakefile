import pandas as pd
import numpy as np
import os
import sys

configfile: "config.json" # use for params in rf, syneromics and explainability

DRUGS = pd.read_csv("data/" + config["y"], usecols=['drug_id']).drug_id.unique()
DRUGS = np.sort(DRUGS)

DRUGS = DRUGS[:2]  # for testing
# print(DRUGS)


for dir in ["data_tmp", "tmp", "exp_results", "syn_results"]:
    if not os.path.exists(dir):
        os.makedirs(dir)




rule all:
    input:
        "exp_results/combined_performances.tsv",  # final output explainability
        "syn_results/final_results.tsv",        # final output syneromics
        "syn_results/tree_performances.tsv"      # final output syneromics



rule create_data:   # this takes about 30 min
    input:
        train = "data/" + config["train"],
        test = "data/" + config["test"],
        response = "data/" + config["y"]
    output:
        train = temp(expand("data_tmp/{drug}_data.csv", drug=DRUGS)),
        test = temp(expand("data_tmp/{drug}_test.csv", drug=DRUGS))
    params:
        max_drug = len(DRUGS),
        nan_removed = config['nan']
    resources:
        mem_mb = 800,
        time='1:00:00'
    script:
        "scripts/create_data.py"   


rule random_forest:  # this takes up to 60 min per cpu job
    input: 
        train = "data_tmp/{drug}_data.csv",
        test = "data_tmp/{drug}_test.csv"
    output:
        trees = temp("tmp/{drug}_aggregated_trees.csv"),
        score = temp("tmp/{drug}_performance.tsv"),
#        imp = temp("tmp/{drug}_importances.csv")
    params:   # make these dynamic for cross validation (can be called with snakemake.params[0] ???)
        drug = lambda wc: wc.get("drug"),
        nTrees = config["nTrees"],
        mtry = config["mtry"],
        minNodeSize = config["minNodeSize"],
        maxDepth = config["maxDepth"],
        workDir = "." 
    resources:
        mem_mb = 2500,
        time='2:00:00'
    script:
        "scripts/ranger_run-parallel.R"

rule syneromics: # this takes up to 25 min per cpu job
    input:
        trees = "tmp/{drug}_aggregated_trees.csv",
        train = "data_tmp/{drug}_data.csv"
    output:
        temp("tmp/{drug}_final_results.tsv")
    params:
        drug = lambda wc: wc.get("drug"),
        maxOrder = config["maxOrder"],
        minReps = config["minReps"]
    resources:
        mem_mb = 4000,
        time='1:00:00'
    script:
        "scripts/syneromics.py"
    
    
        
rule single_proteins:
    input:
        train = "data_tmp/{drug}_data.csv",
        test = "data_tmp/{drug}_test.csv"
    output:
        temp("tmp/{drug}_proteins.csv")
    params:
        drug = lambda wc: wc.get("drug")
    resources:
        mem_mb = 3000,
        time='4:00:00'
    script:
        "scripts/protein_regression.py"



rule explainability:
    input:
        train = "data_tmp/{drug}_data.csv",
        test = "data_tmp/{drug}_test.csv",
        synergies = "tmp/{drug}_final_results.tsv",
        proteins = "tmp/{drug}_proteins.csv"
    output:
        temp("tmp/{drug}_regression.tsv")
    params:
        drug = lambda wc: wc.get("drug"),
        alpha = config["alpha"],
        filter = config["filter"],
        regularized = config["regularized"]
    resources:
        mem_mb = 24000,  #only for regularization needed
        time='6:00:00'
    shell:
        "lasso/bin/python scripts/explainability.py {input.train} {input.test} {input.synergies} {input.proteins} {output} {wildcards.drug} -a {params.alpha} -f {params.filter} -r {params.regularized}"



rule combine:
    input:
        rf_score = expand("tmp/{drug}_performance.tsv", drug=DRUGS),
        synergies = expand("tmp/{drug}_final_results.tsv", drug=DRUGS),
        explained = expand("tmp/{drug}_regression.tsv", drug=DRUGS),
        proteins = expand("tmp/{drug}_proteins.csv", drug=DRUGS)
    output:
        synergies = "syn_results/final_results.tsv",
        rf_scores = "syn_results/tree_performances.tsv",
        exp_scores = "exp_results/combined_performances.tsv",
        exp_models = "exp_results/combined_models.tsv",
        exp_proteins = "exp_results/protein_models.tsv"
    resources:
        mem_mb = 5000,
        time='2:00:00'
    script:
        "scripts/combine.py"
        
        