{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "076c4768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may need to remove the '#' from the following commands to install the required dependencies\n",
    "\n",
    "#these two are to read the excel\n",
    "#! pip install xlrd\n",
    "#! pip install install openpyxl\n",
    "\n",
    "#These are to run R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc145293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "from itertools import combinations\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9c42db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_repetitions=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "911f49ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Cell_Line', 'P37108.SRP14_HUMAN', 'Q96JP5.ZFP91_HUMAN',\n",
       "       'Q9Y4H2.IRS2_HUMAN', 'P36578.RL4_HUMAN', 'Q6SPF0.SAMD1_HUMAN',\n",
       "       'O76031.CLPX_HUMAN', 'Q8WUQ7.CATIN_HUMAN', 'A6NIH7.U119B_HUMAN',\n",
       "       'Q9BTD8.RBM42_HUMAN',\n",
       "       ...\n",
       "       'P33151.CADH5_HUMAN', 'Q5EBL4.RIPL1_HUMAN', 'P49715.CEBPA_HUMAN',\n",
       "       'Q5TA45.INT11_HUMAN', 'O14924.RGS12_HUMAN', 'Q7Z3B1.NEGR1_HUMAN',\n",
       "       'O60669.MOT2_HUMAN', 'Q13571.LAPM5_HUMAN', 'Q96JM2.ZN462_HUMAN',\n",
       "       'P35558.PCKGC_HUMAN'],\n",
       "      dtype='object', length=6693)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One row per cell line\n",
    "x = pd.read_excel('data/ProCan-DepMapSanger_protein_matrix_6692_averaged.xlsx', engine='openpyxl').fillna(0).drop(columns=['Project_Identifier'])\n",
    "c = [a.replace(';','.') for a in x.columns]\n",
    "x.columns = c\n",
    "x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d6587b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/vs05/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3185: DtypeWarning: Columns (24) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['drug_id', 'cell_line_name', 'ln_IC50'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.read_csv('data/DrugResponse_PANCANCER_GDSC1_GDSC2_20200602.csv')[['drug_id','cell_line_name','ln_IC50']]\n",
    "y.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed412bc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This cell is the function to go from the table to a JSON file (variantSpark format and structure)\n",
    "\n",
    "def merge_tree_node(tree, node):\n",
    "    \n",
    "    # Empty tree\n",
    "    if type(tree)==float: return tree\n",
    "    if len(tree)==0: return node\n",
    "\n",
    "    # Direct children\n",
    "    if tree['right'] == node['nodeID']:\n",
    "        tree['right'] = node\n",
    "        return tree\n",
    "    elif tree['left'] == node['nodeID']:\n",
    "        tree['left'] = node\n",
    "        return tree\n",
    "\n",
    "    # Create\n",
    "    right = merge_tree_node(tree['right'], node)\n",
    "    left = merge_tree_node(tree['left'], node)\n",
    "    tree['right'] = right\n",
    "    tree['left'] = left\n",
    "    return tree\n",
    "            \n",
    "\n",
    "def from_table_to_json(m):\n",
    "    tree = {}\n",
    "    for _id,row in m.iterrows():\n",
    "        current_node = {'nodeID': row['nodeID'], \n",
    "                        'splitvarID':row['splitvarID'],\n",
    "                        'splitVar':row['splitvarName'],\n",
    "                        'splitval':row['splitval'], \n",
    "                        'terminal':row['terminal'], \n",
    "                        'prediction':row['prediction'], \n",
    "                        'left':row['leftChild'], \n",
    "                        'right':row['rightChild'] }\n",
    "        tree = merge_tree_node(tree, current_node)\n",
    "    return tree\n",
    "\n",
    "\n",
    "\n",
    "# Test\n",
    "#m = pd.read_csv('output/tree1.csv')\n",
    "#from_table_to_json(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9366be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algorithm to get the interacting nodes (no testing done yet)\n",
    "\n",
    "def get_interactions(tree, current_list, interactions):\n",
    "    if not 'splitVar' in tree.keys():\n",
    "        return 0\n",
    "    if str(tree['splitVar']) == 'nan': return 0 #ranger adds a fake predicting node at the end\n",
    "    \n",
    "    # Adding the interaction\n",
    "    current_list.append(tree['splitVar'])\n",
    "    if len(current_list) >= 2:\n",
    "        for i in range(2,len(current_list)+1):\n",
    "            aux = '+'.join(sorted(current_list[-i:]))\n",
    "            if aux in interactions.keys():\n",
    "                interactions[aux] +=1\n",
    "            else:\n",
    "                interactions[aux] = 1\n",
    "                    \n",
    "    if 'left' in tree.keys():\n",
    "        get_interactions(tree['left'], current_list, interactions)\n",
    "    if 'right' in tree.keys():\n",
    "        get_interactions(tree['right'], current_list, interactions)\n",
    "        \n",
    "    _ = current_list.pop()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9d2981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing all the interactions\n",
    "\n",
    "def test_interactions(df, data):\n",
    "    \"\"\"\n",
    "    I use GLM because:\n",
    "    The main difference between the two approaches is that the general linear model strictly assumes that\n",
    "    the residuals will follow a conditionally normal distribution, while the GLM loosens this assumption \n",
    "    and allows for a variety of other distributions from the exponential family for the residuals.\n",
    "    \"\"\"\n",
    "    final_results = []\n",
    "    counts = 0\n",
    "\n",
    "    for v in df[(df.repetitions>=2) & (df.order ==2)].variants.tolist():\n",
    "        \n",
    "        #preparing the input\n",
    "        sp=v.split('+')\n",
    "        xy = data[sp+['ln_IC50']].fillna(-1)\n",
    "        sp=v.replace('_','').split('+')\n",
    "        xy.columns = [''.join([chr(int(y)+97) if y.isnumeric() else y for y in x.replace('_','').replace('.','')]) for x in xy.columns]\n",
    "        formula = xy.columns[-1]+' ~ '\n",
    "        for i in range(1,len(xy.columns)):\n",
    "            formula = formula + ' + '.join(['*'.join(o) for o in list(combinations(xy.columns[:-1],i))])\n",
    "            formula = formula + ' + '\n",
    "        formula = formula.rstrip(' + ')\n",
    "\n",
    "        # Standard fitting\n",
    "        ols = smf.ols(formula,data=xy)\n",
    "        ols.raise_on_perfect_prediction = False #preventing the perfect separation error\n",
    "        results = ols.fit(disp=False, maxiter=1000) #mehtod prevents singular matrix\n",
    "        results = results.summary()\n",
    "        converged = results.tables[0].data[5][1].strip()\n",
    "        pseudo_r2 = results.tables[0].data[3][3].strip()\n",
    "        results = results.tables[1].data\n",
    "        results = pd.DataFrame(results[1:], columns=['coef_id', 'coef', 'std err', 'z', 'P>|z|', '[0.025', '0.975]'])\n",
    "        results['standard_fitting'] = True\n",
    "\n",
    "        #If nan means no convergence bc singular matrix\n",
    "        #adding regularization\n",
    "        if 'nan' == pd.DataFrame(results)['z'].iloc[2].strip():\n",
    "            try:\n",
    "                results = ols.fit_regularized(method='l1', disp=False, maxiter=1000, alpha=0.3) #mehtod prevents singular matrix\n",
    "                results = results.summary()\n",
    "                converged = results.tables[0].data[5][1].strip()\n",
    "                pseudo_r2 = results.tables[0].data[3][3].strip()\n",
    "                results = results.tables[1].data\n",
    "                results = pd.DataFrame(results[1:], columns=['coef_id', 'coef', 'std err', 'z', 'P>|z|', '[0.025', '0.975]'])\n",
    "                results['standard_fitting'] = False        \n",
    "            except:\n",
    "                #crashed the regularized\n",
    "                counts +=1\n",
    "\n",
    "        results['converged'] = converged\n",
    "        results['pseudo_r2'] = pseudo_r2\n",
    "        results['snps'] = v\n",
    "        results['order'] = len(sp)\n",
    "        final_results.append(results)\n",
    "\n",
    "    final_results = pd.concat(final_results)\n",
    "    #print(counts)\n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ac69667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing all the interactions\n",
    "\n",
    "def results_fit_to_df(results):\n",
    "    coeffs = results.params.tolist()\n",
    "    pvals = results.pvalues.tolist()\n",
    "    pseudo_r2 = results.rsquared\n",
    "    tvals = results.tvalues.tolist()\n",
    "    cint_low = results.conf_int()[0].tolist()\n",
    "    cint_high = results.conf_int()[1].tolist()\n",
    "\n",
    "    results = results.summary()\n",
    "    converged = results.tables[0].data[5][1].strip()\n",
    "    results = results.tables[1].data\n",
    "    results = pd.DataFrame(results[1:], columns=['coef_id', 'coef', 'std err', 'z', 'P>|z|', '[0.025', '0.975]'])\n",
    "    results['P>|z|'] = pvals\n",
    "    results['z'] = tvals \n",
    "    results['coef'] = coeffs\n",
    "    results['converged'] = converged\n",
    "    results['pseudo_r2'] = pseudo_r2\n",
    "    results['[0.025'] = cint_low\n",
    "    results['0.975]'] = cint_high\n",
    "    return results\n",
    "    \n",
    "def test_interactions_high(df, data, max_order=4):\n",
    "    \"\"\"\n",
    "    I use GLM because:\n",
    "    The main difference between the two approaches is that the general linear model strictly assumes that\n",
    "    the residuals will follow a conditionally normal distribution, while the GLM loosens this assumption \n",
    "    and allows for a variety of other distributions from the exponential family for the residuals.\n",
    "    \"\"\"\n",
    "    final_results = []\n",
    "    counts = 0\n",
    "\n",
    "    for m_or in range(2,max_order+1):\n",
    "        print('current order',m_or)\n",
    "        \n",
    "        for v in df[(df.repetitions>=2) & (df.order==m_or)].variants.tolist():\n",
    "            #preparing the input\n",
    "            sp=v.split('+')\n",
    "            xy = data[sp+['ln_IC50']].fillna(-1)\n",
    "            sp=v.replace('_','').split('+')\n",
    "            xy.columns = [''.join([chr(int(y)+97) if y.isnumeric() else y for y in x.replace('_','').replace('.','')]) for x in xy.columns]\n",
    "            formula = xy.columns[-1]+' ~ '\n",
    "            for i in range(1,len(xy.columns)):\n",
    "                formula = formula + ' + '.join(['*'.join(o) for o in list(combinations(xy.columns[:-1],i))])\n",
    "                formula = formula + ' + '\n",
    "            formula = formula.rstrip(' + ')\n",
    "            \n",
    "            #Recreating the formula\n",
    "            if m_or>2:\n",
    "                #gathering all interactions\n",
    "                fs = formula.split(' + ')\n",
    "                formula = ' + '.join([a for a in fs if '*' not in a]+[a for a in fs if a.count('*')== m_or-1])\n",
    "                all_interactions = [a.replace('*',':') for a in fs if '*' in a]\n",
    "                final_results = pd.concat(final_results)\n",
    "                subset = final_results[final_results.coef_id.apply(lambda a: a in all_interactions)].reset_index(drop=True)\n",
    "                final_results = [final_results]\n",
    "                if len(subset)>0:\n",
    "                    max_idx = subset['coef'].astype(float).idxmax()\n",
    "                    coef_id = subset.loc[max_idx].coef_id\n",
    "                    formula = formula +' + '+coef_id.replace(':','*')\n",
    "                else:\n",
    "                    #pass\n",
    "                    continue # bc i dont think it is a valid tree form (interaction-wise)\n",
    "                    #There is no sub epistasis (P>Q>O>P, tree 503, first compound)\n",
    "\n",
    "            # Standard fitting\n",
    "            try:\n",
    "                ols = smf.ols(formula.replace('*',':'),data=xy)\n",
    "                # \"*\" vs \":\" #https://stackoverflow.com/questions/33050104/difference-between-the-interaction-and-term-for-formulas-in-statsmodels-ols\n",
    "            except:\n",
    "                print('error in OLS')\n",
    "                print('coef_id',coef_id)\n",
    "                print('formula OLS',type(formula),formula)\n",
    "                #return pd.concat(final_results)\n",
    "                continue\n",
    "            ols.raise_on_perfect_prediction = False #preventing the perfect separation error\n",
    "            results = ols.fit(disp=False, maxiter=1000) #mehtod prevents singular matrix\n",
    "#            return results\n",
    "            results = results_fit_to_df(results)\n",
    "            results['standard_fitting'] = True\n",
    "\n",
    "            #If nan means no convergence bc singular matrix\n",
    "            #adding regularization\n",
    "            if 'nan' == pd.DataFrame(results)['z'].astype(str).iloc[2].strip():\n",
    "                try:\n",
    "                    results = ols.fit_regularized(method='l1', disp=False, maxiter=1000, alpha=0.3) #mehtod prevents singular matrix\n",
    "                    results = results_fit_to_df(results)\n",
    "                    results['standard_fitting'] = False        \n",
    "                except:\n",
    "                    #crashed the regularized\n",
    "                    counts +=1\n",
    "                    continue\n",
    "\n",
    "\n",
    "            results['snps'] = v\n",
    "            results['order'] = len(sp)\n",
    "            final_results.append(results)\n",
    "\n",
    "    final_results = pd.concat(final_results)\n",
    "    return final_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9152265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'P02511.CRYAB_HUMAN'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def undo(string):\n",
    "    \n",
    "    string = ''.join([ x if ord(x)<90 else str(ord(x)-97) for x in string ])\n",
    "    string = string[:6]+'.'+string[6:].replace('HUMAN', '_HUMAN') #not sure these 6\n",
    "    return string\n",
    "    \n",
    "undo('PacfbbCRYABHUMAN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1ba1343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: tmp: File exists\n",
      "mkdir: output: File exists\n",
      "0 1409 1.2159347534179688e-05\n",
      "current order 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/vs05/lib/python3.8/site-packages/statsmodels/regression/linear_model.py:1918: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current order 3\n",
      "current order 4\n",
      "1 1057 200.8323619365692\n",
      "current order 2\n",
      "current order 3\n",
      "current order 4\n",
      "2 1060 596.8045341968536\n",
      "current order 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/vs05/lib/python3.8/site-packages/statsmodels/regression/linear_model.py:1918: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n",
      "/opt/homebrew/anaconda3/envs/vs05/lib/python3.8/site-packages/statsmodels/regression/linear_model.py:1918: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n",
      "/opt/homebrew/anaconda3/envs/vs05/lib/python3.8/site-packages/statsmodels/regression/linear_model.py:1918: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current order 3\n",
      "current order 4\n",
      "3 252 566.8235251903534\n",
      "current order 2\n",
      "current order 3\n",
      "current order 4\n",
      "4 282 179.82224893569946\n",
      "current order 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/vs05/lib/python3.8/site-packages/statsmodels/regression/linear_model.py:1918: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.sqrt(eigvals[0]/eigvals[-1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current order 3\n",
      "current order 4\n"
     ]
    }
   ],
   "source": [
    "#TODO: By compound\n",
    "\n",
    "#Looping over all drugs\n",
    "# drug_id\n",
    "# Other options:\n",
    "# - drug_name\n",
    "# - CHEMBL = Chemical compound ID\n",
    "#for compound_name, group in x.merge(y, left_on='Cell_Line', right_on='cell_line_name').groupby('drug_id'): # may require too much memory\n",
    "\n",
    "#Making a temp file to run all R stuff\n",
    "! mkdir tmp\n",
    "\n",
    "#Make a folder to save all outputs\n",
    "! mkdir output\n",
    "\n",
    "column_to_group = 'drug_id'\n",
    "drugs_list = y[column_to_group].unique()\n",
    "i = -1\n",
    "start_time = time.time()\n",
    "end_time = time.time()\n",
    "all_drug_results = []\n",
    "for elm in drugs_list[:5]:\n",
    "    i+=1\n",
    "    \n",
    "    if i%10==0 or i<10: print(i,elm, end_time - start_time)\n",
    "    start_time = time.time()\n",
    "\n",
    "    xy = x.merge(y[y[column_to_group]==elm], left_on='Cell_Line', right_on='cell_line_name')\n",
    "    #Enhancement: Remove peptides that are all zero \n",
    "    \n",
    "    # saving csv for R df\n",
    "    # file name is generic but we could personalize it\n",
    "    xy.drop(columns=['Cell_Line', 'cell_line_name','drug_id']).rename(columns={'ln_IC50':'label'}).to_csv(\"tmp/data.csv\", index=False)\n",
    "\n",
    "    #Run the R script to generate the outputs\n",
    "    ! Rscript ranger_run.R\n",
    "    \n",
    "    #load the R outputs (the trees, one file each), and convert it to VS look-alike and get interactions\n",
    "    interactions = {}\n",
    "    trees = os.listdir('output/')\n",
    "    #files = [x for x in files if 'tree' in x]\n",
    "    for tree in trees:\n",
    "        if 'tree' not in tree: continue #if it is not a tree file ignore\n",
    "        tree_json = from_table_to_json(pd.read_csv('output/'+tree))        \n",
    "        get_interactions(tree_json,[],interactions) #the interactions are found in \"interactions\"\n",
    "        \n",
    "    # Creating a df out of the interactions\n",
    "    df = pd.DataFrame({'variants':interactions.keys(),'repetitions':interactions.values()})\n",
    "    df['order'] = df.variants.apply(lambda x: x.count('+')+1)\n",
    "    \n",
    "    \n",
    "    tested_interactions = test_interactions_high(df, xy) #here you define which order of interactions you want to compute\n",
    "    tested_interactions['drug'] = elm\n",
    "    all_drug_results.append(tested_interactions)\n",
    "    end_time = time.time()\n",
    "\n",
    "    \n",
    "\n",
    "final_results = pd.concat(all_drug_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ed752b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order\n",
       "4      172\n",
       "3      177\n",
       "2    39470\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many tested interactions for each order wyou have\n",
    "final_results[final_results.coef_id=='Intercept'].groupby('order').size().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a0dabef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1409, 1057, 1060,  252,  282,  283,  346,  439,  226,  461, 1149,\n",
       "       1494,  223,    1, 1001, 1004, 1005, 1006, 1007, 1008, 1009, 1010,\n",
       "       1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021,\n",
       "       1022, 1023, 1024, 1025, 1026, 1028, 1029, 1030, 1031, 1032, 1033,\n",
       "       1036, 1037, 1038, 1039,  104, 1042, 1043, 1046, 1047, 1048, 1049,\n",
       "       1050, 1052, 1053, 1054, 1058, 1059,  106, 1061, 1062, 1066, 1067,\n",
       "       1069, 1072, 1091,   11,  110,  111, 1114, 1129, 1133, 1135, 1136,\n",
       "       1170, 1175, 1184, 1185,  119, 1192, 1194, 1199, 1218, 1219, 1230,\n",
       "       1236, 1239, 1241, 1242, 1243, 1248, 1259, 1261, 1262, 1263, 1264,\n",
       "       1266, 1268,  127,  133,  134,  135,  136, 1371, 1373, 1374, 1375,\n",
       "       1376, 1377, 1378, 1382, 1386, 1392, 1393, 1394,  140, 1401, 1402,\n",
       "       1403, 1407, 1413, 1414, 1416, 1419, 1421, 1422, 1425, 1426, 1427,\n",
       "       1428, 1429, 1430, 1432, 1433, 1434, 1437, 1441, 1444, 1445, 1446,\n",
       "       1449, 1451, 1453, 1458, 1459, 1460, 1461, 1463, 1464,  147, 1490,\n",
       "       1495, 1496, 1497, 1498,  150, 1502,  151, 1515, 1516, 1517, 1518,\n",
       "       1519,  152, 1520, 1525, 1526, 1527, 1529,  153, 1530, 1534, 1535,\n",
       "        154, 1543, 1544, 1546, 1547, 1548,  155,  156,  157,  158,  159,\n",
       "        163,  164,  165,  166,  167,   17,  170,  171,  172,  173,  175,\n",
       "        176,  177,  178,  179,  180,  182,  184,  185,  186,  190,  192,\n",
       "        193,  194,  196,  197,  199,  200,  201,  202,  203,  204,  205,\n",
       "        206,  207,  208,  211,  219,  221,  222,  224,  225,  228,  229,\n",
       "        230,  231,  235,  236,  238,  245,  249,  253,  254,  255,  256,\n",
       "        257,  258,  260,  261,  262,  263,  264,  265,  266,  268,  269,\n",
       "        271,  272,  273,  274,  275,  276,  277,  279,  281,  284,  285,\n",
       "        286,  287,  288,  289,   29,  290,  291,  292,  293,  294,  295,\n",
       "        298,  299,    3,   30,  300,  301,  302,  303,  304,  305,  306,\n",
       "        308,  309,  310,  312,  317,   32,  326,  328,  329,  330,  331,\n",
       "        332,  333,   34,  341,  342,  344,  345,   35,  356,  362,  363,\n",
       "        366,   37,  371,  372,  374,  375,  376,   38,  380,  381,  382,\n",
       "        406,  407,  408,  409,   41,  410,  412,  415,  416,  427,  431,\n",
       "        432,  435,  436,  437,  438,  442,  446,  447,  449,   45,  476,\n",
       "        477,  478,    5,   51,   52,   53,   54,  546,   55,  552,   56,\n",
       "        562,  563,  573,  574,  576,   59,    6,   60,   62,   63,   64,\n",
       "         71,   83,   86,   87,   88,   89,    9,   91,   94, 1190, 1080,\n",
       "       1511, 1786, 1909, 1084, 1168, 1594, 1995, 1079, 1632, 1549, 1560,\n",
       "       1561, 1564, 1598, 1850, 2460, 1073, 1083, 1003, 1051, 1064, 1068,\n",
       "       1074, 1085, 1088, 1089, 1092, 1093, 1169, 1179, 1191, 1193, 1200,\n",
       "       1237, 1372, 1510, 1512, 1558, 1559, 1563, 1735, 1851, 1864, 1866,\n",
       "       1873, 1908, 1910, 1912, 1913, 1915, 1916, 1917, 1918, 1919, 1922,\n",
       "       1924, 1925, 1926, 1927, 1928, 1930, 1931, 1932, 1933, 1934, 1936,\n",
       "       1937, 1938, 1939, 1940, 1941, 1942, 1944, 1945, 1946, 1947, 1949,\n",
       "       1954, 1956, 1957, 1958, 1959, 1960, 1961, 1962, 1964, 1965, 1966,\n",
       "       1967, 1968, 1970, 1971, 1972, 1973, 1975, 1980, 1982, 1985, 1986,\n",
       "       1987, 1989, 1990, 1991, 1993, 1996, 1997, 1998, 2013, 2014, 2015,\n",
       "       2016, 2018, 2020, 2021, 2022, 2023, 2024, 2026, 2027, 2028, 2034,\n",
       "       2040, 2041, 2042, 2043, 2044, 2045, 2047, 2048, 2063, 2066, 2071,\n",
       "       2074, 2075, 2076, 2077, 2078, 2079, 2080, 2081, 2084, 2090, 2096,\n",
       "       2103, 2106, 2107, 2109, 2110, 2111, 2125, 2152, 2161, 2162, 2164,\n",
       "       2170, 2173, 2182, 2220, 2235, 2243, 2252, 2253, 2254, 2255, 2257,\n",
       "       2258, 2259, 2260, 2282, 2303, 2308, 2466, 2503, 2504, 2505, 2508,\n",
       "       2509, 2510, 1911, 2046, 2160, 2176, 2177, 2290, 1034, 1862, 2093,\n",
       "        428, 1436,  474, 1086, 1867, 2163, 2313, 1789, 1796, 1797, 1055,\n",
       "       1056, 1078, 1081, 1082, 1094, 1131, 1134, 1150, 1177, 1180, 1189,\n",
       "       1201, 1249, 1250, 1504, 1506, 1507, 1553, 1557, 1562, 1576, 1578,\n",
       "       1579, 1593, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622,\n",
       "       1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1633, 1634, 1635,\n",
       "       1788, 1790, 1791, 1794, 1798, 1799, 1800, 1849, 1853, 1854, 1855,\n",
       "       1856, 1857, 1858, 1868, 1869, 1871, 1923, 1929, 2097, 2098, 2099,\n",
       "       2100, 2104, 2105, 2108, 2150, 2151, 2153, 2166, 2168, 2169, 2171,\n",
       "       2172, 2175, 2178, 2179, 2180, 2181, 2183, 2184, 2256, 2261, 2266,\n",
       "       2268, 2269, 2270, 2271, 2272, 2273, 2274, 2276, 2277, 2279, 2280,\n",
       "       2281, 2283, 2284, 2286, 2288, 2289, 2291, 2292, 2293, 2294, 2295,\n",
       "       2296, 2297, 2298, 2299, 2300, 2302, 2304, 2305, 2306, 2307, 2309,\n",
       "       2310, 2312, 2315, 2316, 2317, 2318, 2319, 2320, 2322, 2323, 2324,\n",
       "       2325, 2326, 2327, 2328, 2329, 2330, 2331, 2332, 2333, 2365, 2463,\n",
       "       1090, 1096, 1116, 1514, 1613, 1787, 1792, 1793, 1852, 1872, 2101,\n",
       "       2174, 1142, 1143, 1158, 1161, 1164, 1166, 1203, 2127, 2321, 2354,\n",
       "       2359, 2363, 1550, 1551, 1552, 1554, 1545, 2265, 2459, 2502, 2638])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
